{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049f3d29-004c-44ea-9382-ad0f5ef25204",
   "metadata": {},
   "source": [
    "# eCommerce Transactions Data Science Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f79b69a-3650-4a56-b65e-76045ebcf09d",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This assignment involves performing exploratory data analysis (EDA), building a Lookalike Model, and performing customer segmentation on an eCommerce transactions dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1b2e0-057e-4d8f-a973-06fa75fe448e",
   "metadata": {},
   "source": [
    "### Dataset Files\n",
    "1. **Customers.csv**: Contains customer information.\n",
    "2. **Products.csv**: Contains product information.\n",
    "3. **Transactions.csv**: Contains transaction details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200e5cc-5569-4ebf-be0c-7ef0c7fe4190",
   "metadata": {},
   "source": [
    "### Tasks\n",
    " 1. **Task 1**: Perform EDA and derive business insights.\n",
    " 2. **Task 2**: Build a Lookalike Model.\n",
    " 3. **Task 3**: Perform Customer Segmentation using clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc5bb0c-0805-4c38-8aa5-e8ff969b54fb",
   "metadata": {},
   "source": [
    "# Task 2: Lookalike Model for Customer Similarity\n",
    "\n",
    "This notebook builds a Lookalike Model that recommends 3 similar customers based on a user's profile and transaction history. The model uses both customer and product information and assigns a similarity score to each recommended customer.\n",
    " \n",
    "#### Steps:\n",
    " 1. Load and preprocess data.\n",
    " 2. Perform feature engineering.\n",
    " 3. Compute similarity scores using Cosine Similarity.\n",
    " 4. Generate top 3 lookalikes for the first 20 customers.\n",
    " 5. Save results in `Lookalike.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b5c2a1-0f64-4b88-ae00-3b74f3f940b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5762eb5-105d-48a9-87c6-6a8132124ec6",
   "metadata": {},
   "source": [
    "## Step 1: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74bb9878-89f6-470f-80ea-18d7b603d409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Data:\n",
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "\n",
      "Transactions Data:\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n",
      "\n",
      "Products Data:\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n"
     ]
    }
   ],
   "source": [
    "def load_data(customers_path, transactions_path, products_path):\n",
    "    \"\"\"\n",
    "    Load customer, transaction, and product data from CSV files.\n",
    "    \n",
    "    Args:\n",
    "        customers_path (str): Path to Customers.csv.\n",
    "        transactions_path (str): Path to Transactions.csv.\n",
    "        products_path (str): Path to Products.csv.\n",
    "    \n",
    "    Returns:\n",
    "        customers (pd.DataFrame): Customer data.\n",
    "        transactions (pd.DataFrame): Transaction data.\n",
    "        products (pd.DataFrame): Product data.\n",
    "    \"\"\"\n",
    "    customers = pd.read_csv(customers_path)\n",
    "    transactions = pd.read_csv(transactions_path)\n",
    "    products = pd.read_csv(products_path)\n",
    "    return customers, transactions, products\n",
    "\n",
    "# Load data\n",
    "customers, transactions, products = load_data('Customers.csv', 'Transactions.csv', 'Products.csv')\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Customers Data:\")\n",
    "print(customers.head())\n",
    "\n",
    "print(\"\\nTransactions Data:\")\n",
    "print(transactions.head())\n",
    "\n",
    "print(\"\\nProducts Data:\")\n",
    "print(products.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2115b-4c44-4f2d-b0d4-1c25b05414db",
   "metadata": {},
   "source": [
    "### Step 2: Feature Engineering\n",
    " \n",
    " Combine customer, transaction, and product data to create meaningful features for each customer. Examples of features include:\n",
    " - **Demographics**: Age, Gender.\n",
    " - **Transaction History**: Total spend, frequency of purchases, average transaction value.\n",
    " - **Product Preferences**: Categories of products purchased, brands preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb42ef34-037b-4fc8-9093-c876646dc1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered Features:\n",
      "  CustomerID         Region  TotalSpend  TotalQuantity  TransactionFrequency  \\\n",
      "0      C0001  South America     3354.52             12                     5   \n",
      "1      C0002           Asia     1862.74             10                     4   \n",
      "2      C0003  South America     2725.38             14                     4   \n",
      "3      C0004  South America     5354.88             23                     8   \n",
      "4      C0005           Asia     2034.24              7                     3   \n",
      "\n",
      "  PreferredCategory  Tenure  \n",
      "0       Electronics     931  \n",
      "1          Clothing    1078  \n",
      "2        Home Decor     325  \n",
      "3             Books     840  \n",
      "4       Electronics     895  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(customers, transactions, products):\n",
    "    \"\"\"\n",
    "    Merge datasets and create customer-level features.\n",
    "    \n",
    "    Args:\n",
    "        customers (pd.DataFrame): Customer data.\n",
    "        transactions (pd.DataFrame): Transaction data.\n",
    "        products (pd.DataFrame): Product data.\n",
    "    \n",
    "    Returns:\n",
    "        features (pd.DataFrame): Engineered features for each customer.\n",
    "    \"\"\"\n",
    "    # Merge datasets\n",
    "    customer_transactions = pd.merge(customers, transactions, on='CustomerID')\n",
    "    customer_transactions = pd.merge(customer_transactions, products, on='ProductID')\n",
    "    \n",
    "    # Feature engineering\n",
    "    features = customer_transactions.groupby('CustomerID').agg({\n",
    "        'Region': 'first',\n",
    "        'SignupDate': 'first',\n",
    "        'TotalValue': 'sum',\n",
    "        'Quantity': 'sum',\n",
    "        'TransactionID': 'count',\n",
    "        'Category': lambda x: x.mode()[0]\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate tenure\n",
    "    features['Tenure'] = (pd.Timestamp.now() - pd.to_datetime(features['SignupDate'])).dt.days\n",
    "    features = features.drop(columns=['SignupDate'])\n",
    "    \n",
    "    # Rename columns\n",
    "    features.columns = ['CustomerID', 'Region', 'TotalSpend', 'TotalQuantity', 'TransactionFrequency', 'PreferredCategory', 'Tenure']\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Perform feature engineering\n",
    "features = preprocess_data(customers, transactions, products)\n",
    "\n",
    "# Display engineered features\n",
    "print(\"Engineered Features:\")\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd82f89d-f671-46f6-aefd-a9f5c81cedd9",
   "metadata": {},
   "source": [
    "### Step 3: Normalize Features\n",
    " \n",
    "Normalize numerical features to ensure they are on the same scale. This is important for computing similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf61275c-8e22-48b6-ade2-5c5f39a54e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Features:\n",
      "   TotalSpend  TotalQuantity  TransactionFrequency    Tenure CustomerID\n",
      "0    0.308942       0.354839                   0.4  0.842204      C0001\n",
      "1    0.168095       0.290323                   0.3  0.979458      C0002\n",
      "2    0.249541       0.419355                   0.3  0.276377      C0003\n",
      "3    0.497806       0.709677                   0.7  0.757236      C0004\n",
      "4    0.184287       0.193548                   0.2  0.808590      C0005\n"
     ]
    }
   ],
   "source": [
    "def normalize_features(features):\n",
    "    \"\"\"\n",
    "    Normalize numerical features using Min-Max scaling.\n",
    "    \n",
    "    Args:\n",
    "        features (pd.DataFrame): Engineered features.\n",
    "    \n",
    "    Returns:\n",
    "        features_normalized (pd.DataFrame): Normalized features.\n",
    "    \"\"\"\n",
    "    # Normalize numerical features\n",
    "    scaler = MinMaxScaler()\n",
    "    features_normalized = scaler.fit_transform(features[['TotalSpend', 'TotalQuantity', 'TransactionFrequency', 'Tenure']])\n",
    "    \n",
    "    # Convert normalized features back to a DataFrame\n",
    "    features_normalized = pd.DataFrame(features_normalized, columns=['TotalSpend', 'TotalQuantity', 'TransactionFrequency', 'Tenure'])\n",
    "    features_normalized['CustomerID'] = features['CustomerID']\n",
    "    \n",
    "    return features_normalized\n",
    "\n",
    "# Normalize features\n",
    "features_normalized = normalize_features(features)\n",
    "\n",
    "# Display normalized features\n",
    "print(\"Normalized Features:\")\n",
    "print(features_normalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f1717-df3d-47ee-9a02-5a22474acfd8",
   "metadata": {},
   "source": [
    "### Step 4: One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ba1396-465a-4732-a764-56c31d148dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Features:\n",
      "   TotalSpend  TotalQuantity  TransactionFrequency    Tenure CustomerID  \\\n",
      "0    0.308942       0.354839                   0.4  0.842204      C0001   \n",
      "1    0.168095       0.290323                   0.3  0.979458      C0002   \n",
      "2    0.249541       0.419355                   0.3  0.276377      C0003   \n",
      "3    0.497806       0.709677                   0.7  0.757236      C0004   \n",
      "4    0.184287       0.193548                   0.2  0.808590      C0005   \n",
      "\n",
      "   Region_Asia  Region_Europe  Region_North America  Region_South America  \\\n",
      "0        False          False                 False                  True   \n",
      "1         True          False                 False                 False   \n",
      "2        False          False                 False                  True   \n",
      "3        False          False                 False                  True   \n",
      "4         True          False                 False                 False   \n",
      "\n",
      "   PreferredCategory_Books  PreferredCategory_Clothing  \\\n",
      "0                    False                       False   \n",
      "1                    False                        True   \n",
      "2                    False                       False   \n",
      "3                     True                       False   \n",
      "4                    False                       False   \n",
      "\n",
      "   PreferredCategory_Electronics  PreferredCategory_Home Decor  \n",
      "0                           True                         False  \n",
      "1                          False                         False  \n",
      "2                          False                          True  \n",
      "3                          False                         False  \n",
      "4                           True                         False  \n"
     ]
    }
   ],
   "source": [
    "def encode_categorical_features(features, features_normalized):\n",
    "    \"\"\"\n",
    "    One-hot encode categorical features and add them to the normalized DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        features (pd.DataFrame): Engineered features.\n",
    "        features_normalized (pd.DataFrame): Normalized features.\n",
    "    \n",
    "    Returns:\n",
    "        features_encoded (pd.DataFrame): Normalized and encoded features.\n",
    "    \"\"\"\n",
    "    # One-hot encode categorical features\n",
    "    features_encoded = pd.get_dummies(features, columns=['Region', 'PreferredCategory'])\n",
    "    \n",
    "    # Add one-hot encoded features to the normalized DataFrame\n",
    "    for col in features_encoded.columns:\n",
    "        if col.startswith('Region_') or col.startswith('PreferredCategory_'):\n",
    "            features_normalized[col] = features_encoded[col]\n",
    "    \n",
    "    return features_normalized\n",
    "\n",
    "# Encode categorical features\n",
    "features_normalized = encode_categorical_features(features, features_normalized)\n",
    "\n",
    "# Display encoded features\n",
    "print(\"Encoded Features:\")\n",
    "print(features_normalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6879f72b-675a-4b0e-9607-f976f3ce495e",
   "metadata": {},
   "source": [
    "### Step 5: Compute Similarity Scores\n",
    " \n",
    "Use **Cosine Similarity** to compute similarity scores between customers. Cosine Similarity is a good choice for high-dimensional data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd7454da-b576-45a0-9eb8-3215e795ac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix:\n",
      "CustomerID     C0001     C0002     C0003     C0004     C0005     C0006  \\\n",
      "CustomerID                                                               \n",
      "C0001       1.000000  0.351832  0.579095  0.676631  0.645342  0.594865   \n",
      "C0002       0.351832  1.000000  0.190183  0.357436  0.655801  0.208705   \n",
      "C0003       0.579095  0.190183  1.000000  0.607893  0.159246  0.584962   \n",
      "C0004       0.676631  0.357436  0.607893  1.000000  0.302159  0.945626   \n",
      "C0005       0.645342  0.655801  0.159246  0.302159  1.000000  0.179330   \n",
      "\n",
      "CustomerID     C0007     C0008     C0009     C0010  ...     C0191     C0192  \\\n",
      "CustomerID                                          ...                       \n",
      "C0001       0.655570  0.298605  0.196858  0.302921  ...  0.575560  0.993658   \n",
      "C0002       0.664893  0.252708  0.578864  0.647394  ...  0.182292  0.320449   \n",
      "C0003       0.171429  0.595902  0.100926  0.183437  ...  0.579475  0.559278   \n",
      "C0004       0.322482  0.416105  0.196759  0.330387  ...  0.936173  0.630306   \n",
      "C0005       0.999075  0.205868  0.177886  0.261997  ...  0.152611  0.637461   \n",
      "\n",
      "CustomerID     C0193     C0194     C0195     C0196     C0197     C0198  \\\n",
      "CustomerID                                                               \n",
      "C0001       0.300179  0.237045  0.550092  0.357884  0.623787  0.298352   \n",
      "C0002       0.639373  0.197858  0.157051  0.354386  0.269026  0.657220   \n",
      "C0003       0.186099  0.198304  0.982063  0.575909  0.154462  0.129122   \n",
      "C0004       0.645263  0.641521  0.619194  0.387784  0.280921  0.264353   \n",
      "C0005       0.622294  0.163102  0.127350  0.309608  0.612457  0.289920   \n",
      "\n",
      "CustomerID     C0199     C0200  \n",
      "CustomerID                      \n",
      "C0001       0.645928  0.306701  \n",
      "C0002       0.304111  0.947128  \n",
      "C0003       0.172319  0.220526  \n",
      "C0004       0.317596  0.375874  \n",
      "C0005       0.628702  0.597353  \n",
      "\n",
      "[5 rows x 199 columns]\n"
     ]
    }
   ],
   "source": [
    "def compute_similarity(features_normalized):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between customers.\n",
    "    \n",
    "    Args:\n",
    "        features_normalized (pd.DataFrame): Normalized and encoded features.\n",
    "    \n",
    "    Returns:\n",
    "        similarity_matrix (np.ndarray): Cosine similarity matrix.\n",
    "        similarity_df (pd.DataFrame): Similarity matrix as a DataFrame.\n",
    "    \"\"\"\n",
    "    # Compute cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(features_normalized.drop('CustomerID', axis=1))\n",
    "    \n",
    "    # Convert similarity matrix to a DataFrame\n",
    "    similarity_df = pd.DataFrame(similarity_matrix, index=features_normalized['CustomerID'], columns=features_normalized['CustomerID'])\n",
    "    \n",
    "    return similarity_matrix, similarity_df\n",
    "\n",
    "# Compute similarity scores\n",
    "similarity_matrix, similarity_df = compute_similarity(features_normalized)\n",
    "\n",
    "# Display similarity matrix\n",
    "print(\"Similarity Matrix:\")\n",
    "print(similarity_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ede53f-12a5-4ab8-b3c6-49d0a0b5b31d",
   "metadata": {},
   "source": [
    "### Step 5: Generate Top 3 Lookalikes\n",
    " \n",
    "For each of the first 20 customers (C0001 - C0020), find the top 3 most similar customers and their similarity scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd52f5e3-1f6e-4c2a-9074-a096826441c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookalike Recommendations:\n",
      "C0001: [('C0112', 0.9884238286228844), ('C0192', 0.9936579522253058), ('C0184', 0.9940860392728573)]\n",
      "C0002: [('C0106', 0.9886648636130803), ('C0040', 0.9921200427077677), ('C0134', 0.9925276872555436)]\n",
      "C0003: [('C0076', 0.9955701479019959), ('C0031', 0.9956515859335413), ('C0052', 0.9965122787711371)]\n",
      "C0004: [('C0169', 0.9923454037920215), ('C0155', 0.9932083539079324), ('C0165', 0.9937352037310774)]\n",
      "C0005: [('C0186', 0.9736900443509858), ('C0140', 0.9834630435232143), ('C0007', 0.9990750616371955)]\n",
      "C0006: [('C0126', 0.9921318224633991), ('C0191', 0.9936258028507181), ('C0137', 0.994825896280192)]\n",
      "C0007: [('C0186', 0.9666653205856185), ('C0140', 0.9775220458438616), ('C0005', 0.9990750616371955)]\n",
      "C0008: [('C0189', 0.953679390764243), ('C0065', 0.9789643919640681), ('C0059', 0.9829013459966449)]\n",
      "C0009: [('C0010', 0.9736906570486986), ('C0062', 0.9852869238052722), ('C0061', 0.991424164562953)]\n",
      "C0010: [('C0103', 0.9875572129307074), ('C0061', 0.9905000796764254), ('C0062', 0.9952578512563742)]\n",
      "C0011: [('C0168', 0.9954320104776138), ('C0171', 0.9966713383165217), ('C0174', 0.9985209872119576)]\n",
      "C0012: [('C0003', 0.9691404708335296), ('C0163', 0.9725942223927181), ('C0195', 0.9962477414103281)]\n",
      "C0013: [('C0107', 0.9460324061580522), ('C0108', 0.9502243790438352), ('C0099', 0.9725281016878389)]\n",
      "C0014: [('C0164', 0.9156209067256328), ('C0172', 0.9228828809473512), ('C0089', 0.9799193362467123)]\n",
      "C0015: [('C0036', 0.9821875802443065), ('C0185', 0.982742956437571), ('C0094', 0.9854553806361945)]\n",
      "C0016: [('C0067', 0.991543815007422), ('C0030', 0.9948276917089417), ('C0183', 0.9991119475370256)]\n",
      "C0017: [('C0081', 0.9867407581997031), ('C0075', 0.9901976807026055), ('C0041', 0.9951833917887587)]\n",
      "C0018: [('C0194', 0.9849491654876352), ('C0117', 0.9907648652651899), ('C0046', 0.9929272347108467)]\n",
      "C0019: [('C0132', 0.982806515226692), ('C0121', 0.985614758912338), ('C0135', 0.9884376256384683)]\n",
      "C0020: [('C0157', 0.9494463772030726), ('C0035', 0.9597123208974722), ('C0050', 0.9740971999669463)]\n"
     ]
    }
   ],
   "source": [
    "def generate_lookalikes(similarity_matrix, features_normalized, top_n=3, num_customers=20):\n",
    "    \"\"\"\n",
    "    Generate top N lookalikes for the first M customers.\n",
    "    \n",
    "    Args:\n",
    "        similarity_matrix (np.ndarray): Cosine similarity matrix.\n",
    "        features_normalized (pd.DataFrame): Normalized and encoded features.\n",
    "        top_n (int): Number of lookalikes to recommend.\n",
    "        num_customers (int): Number of customers to process.\n",
    "    \n",
    "    Returns:\n",
    "        lookalike_map (dict): Map of customer IDs to their top N lookalikes and similarity scores.\n",
    "    \"\"\"\n",
    "    lookalike_map = {}\n",
    "    \n",
    "    # Iterate over the first M customers\n",
    "    for i in range(num_customers):\n",
    "        customer_id = features_normalized.iloc[i]['CustomerID']\n",
    "        similarity_scores = similarity_matrix[i]\n",
    "        \n",
    "        # Exclude the customer themselves and get the top N similar customers\n",
    "        top_indices = np.argsort(similarity_scores)[-top_n-1:-1]  # Exclude self and get top N\n",
    "        top_customers = [(features_normalized.iloc[idx]['CustomerID'], similarity_scores[idx]) for idx in top_indices]\n",
    "        \n",
    "        # Store the results in the dictionary\n",
    "        lookalike_map[customer_id] = top_customers\n",
    "    \n",
    "    return lookalike_map\n",
    "\n",
    "# Generate lookalikes\n",
    "lookalike_map = generate_lookalikes(similarity_matrix, features_normalized)\n",
    "\n",
    "# Display lookalike recommendations\n",
    "print(\"Lookalike Recommendations:\")\n",
    "for cust_id, similar_customers in lookalike_map.items():\n",
    "    print(f\"{cust_id}: {similar_customers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b08e7ee-8d49-4626-bad0-d9dbfb6e105d",
   "metadata": {},
   "source": [
    "### Step 6: Save Results to `Lookalike.csv`\n",
    " \n",
    "Save the lookalike recommendations in the required format: `Map<cust_id, List<cust_id, score>>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4b2608a-9b67-43b3-bd47-7ca7c6c2c38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Likhith_Varigonda_Lookalike.csv\n"
     ]
    }
   ],
   "source": [
    "def save_results(lookalike_map, output_path='Likhith_Varigonda_Lookalike.csv'):\n",
    "    \"\"\"\n",
    "    Save lookalike recommendations to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        lookalike_map (dict): Map of customer IDs to their top N lookalikes and similarity scores.\n",
    "        output_path (str): Path to save the output CSV file.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        for cust_id, similar_customers in lookalike_map.items():\n",
    "            f.write(f\"{cust_id}, {similar_customers}\\n\")\n",
    "    \n",
    "    print(f\"Results saved to {output_path}\")\n",
    "\n",
    "# Save results\n",
    "save_results(lookalike_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105541dc-bd20-4a92-acd4-9399f84bcb7d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The Lookalike Model successfully identifies similar customers based on their profiles and transaction history. By leveraging feature engineering, normalization, and similarity computation, the model provides actionable insights for personalized marketing strategies. The results are saved in `Lookalike.csv`, which can be used for further analysis or integration into marketing workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0554215-1b10-4133-88be-20ea3ff75dd5",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- **Task 1**: EDA and business insights were derived.\n",
    "- **Task 2**: A Lookalike Model was built and recommendations were saved.\n",
    "- **Task 3**: Customer segmentation was performed using K-Means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f5992-2a6e-4971-a524-78c83c05f896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
